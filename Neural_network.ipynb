{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# These are XOR inputs\n",
    "x=np.array([[0,0,1,1],[0,1,0,1]])\n",
    "# These are XOR outputs\n",
    "y=np.array([[0,1,1,0]])\n",
    "# Number of inputs\n",
    "input_layer = 2\n",
    "# Number of neurons in output layer\n",
    "output_layer = 1\n",
    "# Number of neurons in hidden layer\n",
    "hidden_layer = 2\n",
    "# Total training examples\n",
    "m = x.shape[1]\n",
    "# Learning rate\n",
    "lr = 0.1\n",
    "# Define random seed for consistent results\n",
    "np.random.seed(2)\n",
    "# Define weight matrices for neural network\n",
    "w1 = np.random.rand(hidden_layer,input_layer)   # Weight matrix for hidden layer\n",
    "w2 = np.random.rand(output_layer,hidden_layer)   # Weight matrix for output layer\n",
    "# I didnt use bias units\n",
    "# We will use this list to accumulate losses\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used sigmoid activation function for hidden layer and output\n",
    "def sigmoid(z):\n",
    "    z= 1/(1+np.exp(-z))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def feedForward(w1,w2,x):\n",
    "    z1 = np.dot(w1,x)\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(w2,a1)\n",
    "    a2 = sigmoid(z2)\n",
    "    return z1,a1,z2,a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "def backProp(m,w1,w2,z1,a1,z2,a2,y):\n",
    "\n",
    "    dz2 = a2-y\n",
    "    dw2 = np.dot(dz2,a1.T)/m\n",
    "    dz1 = np.dot(w2.T,dz2) * a1*(1-a1)\n",
    "    dw1 = np.dot(dz1,x.T)/m\n",
    "    dw1 = np.reshape(dw1,w1.shape)\n",
    "\n",
    "    dw2 = np.reshape(dw2,w2.shape)\n",
    "    return dz2,dw2,dz1,dw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "for i in range(epochs):\n",
    "    z1,a1,z2,a2 = feedForward(w1,w2,x)\n",
    "    loss = -(1/m)*np.sum(y*np.log(a2)+(1-y)*np.log(1-a2))\n",
    "    losses.append(loss)\n",
    "    da2,dw2,dz1,dw1 = backProp(m,w1,w2,z1,a1,z2,a2,y)\n",
    "    w2 = w2-lr*dw2\n",
    "    w1 = w1-lr*dw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w1,w2,input):\n",
    "    z1,a1,z2,a2 = feedForward(w1,w2,test)\n",
    "    a2 = np.squeeze(a2)\n",
    "    if a2>=0.5:\n",
    "        print(\"For input\", [i[0] for i in input], \"output is 1\")# ['{:.2f}'.format(i) for i in x])\n",
    "    else:\n",
    "        print(\"For input\", [i[0] for i in input], \"output is 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
